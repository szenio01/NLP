# Natural Language Processing Assignments

This repository contains three assignments focusing on different aspects of Natural Language Processing (NLP). Each assignment explores a distinct concept, providing hands-on experience with real-world NLP tasks and techniques.

## Assignments

### 1. AI_NLP_Assignment1.ipynb
**Title:** Text Corpora and Language Modelling  
- Focuses on exploring text data and building **N-gram language models**.  
- The assignment uses the **Penn Treebank** and **TEDx talks** corpora to examine language properties and estimate models for different values of N.  
- Tasks include examining datasets, understanding linguistic properties, and implementing N-gram models.

---

### 2. AI_NLP_Assignment2.ipynb
**Title:** Probing the Capabilities of Large Language Models (LLMs)  
- Investigates the inner workings of LLMs, with an emphasis on **masked language modeling** using models like BERT.  
- The goal is to analyze and interpret the predictions of language models to probe their alignment with human language use and knowledge.  
- Explores LLM capabilities without requiring additional coding, focusing on analysis and theoretical understanding.

---

### 3. AI_NLP_Assignment3.ipynb
**Title:** Recurrent Models and Word Sense Disambiguation  
- Covers embeddings and **recurrent neural networks (RNNs)** in NLP tasks.  
- Includes hands-on work with contextual embeddings from transformer models for **word sense disambiguation** following methodologies from influential research (e.g., Peters et al., 2018).  
- Combines embeddings with neural architectures to address NLP challenges.

---

## Contributors
- Andreas Alexandrou  
- Nikolas Stavrou  
- Sotiris Zenios
